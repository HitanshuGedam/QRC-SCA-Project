{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec22517-00e3-4704-a652-677f068c75c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install tensorflow[and-cuda] numpy h5py matplotlib tqdm scipy reservoirpy keras pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "079426f2-cd46-4abb-ab64-56e105a00f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import reservoirpy as rpy\n",
    "import h5py\n",
    "import numpy as np\n",
    "import sklearn\n",
    "ascad_path = r\"F:\\QRC-SCA-Project\\ASCAD_data\\ASCAD_data\\ASCAD_databases\\ASCAD.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b91a388c-bb67-4049-bc8f-b832c448d954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 700) (50000,)\n",
      "(10000, 700) (10000,)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(ascad_path, \"r\") as f:\n",
    "    # Profiling (training) set\n",
    "    X_profiling = np.array(f[\"Profiling_traces/traces\"])\n",
    "    Y_profiling = np.array(f[\"Profiling_traces/labels\"])\n",
    "\n",
    "    # Attack (test) set\n",
    "    X_attack = np.array(f[\"Attack_traces/traces\"])\n",
    "    Y_attack = np.array(f[\"Attack_traces/labels\"])\n",
    "\n",
    "print(X_profiling.shape, Y_profiling.shape)\n",
    "print(X_attack.shape, Y_attack.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe3e93a2-fa04-4870-a138-876e36bfa671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n",
      "Profiling Traces: (50000, 700), Attack Traces: (10000, 700)\n",
      "  -> Attack (HW=4) traces count: 239\n",
      "  -> Attack (HW=4) traces count: 260\n",
      "NEW U_train shape (approx 697k steps): (697000, 4)\n",
      "\n",
      "--- Final Data Structure ---\n",
      "Training Input U_train shape: (697000, 4)\n",
      "Test Input U_test shape: (697000, 4)\n",
      "Data saved to .npy files for Stage 2 & 3.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# --- Project Constants ---\n",
    "FILE_PATH = r\"F:\\QRC-SCA-Project\\ASCAD_data\\ASCAD_data\\ASCAD_databases\\ASCAD.h5\" \n",
    "WINDOW_SIZE = 4            # D_in = 4 (for 4 qubits)\n",
    "STRIDE = 1                 \n",
    "QUANTUM_RANGE_MAX = 2 * np.pi \n",
    "TARGET_HW = 4              # Target Hamming Weight for binary detection \n",
    "\n",
    "def load_ascad_data(file_path):\n",
    "    \"\"\"Loads traces and labels using the correct ASCAD HDF5 structure.\"\"\"\n",
    "    try:\n",
    "        with h5py.File(file_path, 'r') as f:\n",
    "            # CORRECTED PATHS based on your working code\n",
    "            X_prof = np.array(f['Profiling_traces/traces']) \n",
    "            Y_prof = np.array(f['Profiling_traces/labels']) \n",
    "\n",
    "            X_att = np.array(f['Attack_traces/traces'])\n",
    "            Y_att = np.array(f['Attack_traces/labels'])\n",
    "            \n",
    "            print(f\"Data loaded successfully!\")\n",
    "            print(f\"Profiling Traces: {X_prof.shape}, Attack Traces: {X_att.shape}\")\n",
    "            return X_prof, Y_prof, X_att, Y_att\n",
    "    except Exception as e:\n",
    "        print(f\"CRITICAL ERROR loading HDF5 file: {e}\")\n",
    "        # Terminate if data loading fails\n",
    "        raise SystemExit(e)\n",
    "\n",
    "def to_binary_hw_detection(Y_raw, target_hw):\n",
    "    \"\"\"Converts 256-class S-Box labels to binary detection labels (0 or 1).\"\"\"\n",
    "    # 1. Compute Hamming Weight (HW) of S-box output (0 to 255)\n",
    "    HW = np.array([bin(n).count(\"1\") for n in range(0, 256)])\n",
    "    Y_hw = HW[Y_raw]\n",
    "    \n",
    "    # 2. Binary Label: 1 if HW == target_hw (Attack), 0 otherwise (Normal)\n",
    "    Y_binary = (Y_hw == target_hw).astype(int)\n",
    "    print(f\"  -> Attack (HW={target_hw}) traces count: {np.sum(Y_binary)}\")\n",
    "    return Y_binary\n",
    "\n",
    "def window_and_normalize(X_traces, Y_labels, window_size, stride, min_val, max_val):\n",
    "    \"\"\"Performs time-series windowing and then normalizes features.\"\"\"\n",
    "    windows = []\n",
    "    window_labels = []\n",
    "    \n",
    "    for trace, label in zip(X_traces, Y_labels):\n",
    "        for i in range(0, len(trace) - window_size + 1, stride):\n",
    "            windows.append(trace[i:i + window_size])\n",
    "            window_labels.append(label)\n",
    "\n",
    "    U = np.array(windows, dtype=np.float32)\n",
    "    Y = np.array(window_labels, dtype=np.int32)\n",
    "    \n",
    "    # Normalization: U_normalized = (U - Min) / (Max - Min) * QUANTUM_RANGE_MAX\n",
    "    U_normalized = (U - min_val) / (max_val - min_val) * QUANTUM_RANGE_MAX\n",
    "    \n",
    "    return U_normalized, Y\n",
    "\n",
    "# --- Main Data Execution ---\n",
    "# --- Main Data Execution (REVISED) ---\n",
    "# ... (rest of the code remains the same)\n",
    "\n",
    "X_prof_raw, Y_prof_raw, X_att_raw, Y_att_raw = load_ascad_data(FILE_PATH)\n",
    "\n",
    "# NEW: CRITICAL DOWN-SAMPLING STEP\n",
    "N_TRAIN_TRACES_POC = 1000  # Use only the first 1,000 profiling traces\n",
    "N_TEST_TRACES_POC = 1000   # Use only the first 1,000 attack traces for a balanced PoC test\n",
    "\n",
    "X_prof_poc = X_prof_raw[:N_TRAIN_TRACES_POC]\n",
    "Y_prof_poc = Y_prof_raw[:N_TRAIN_TRACES_POC]\n",
    "X_att_poc = X_att_raw[:N_TEST_TRACES_POC]\n",
    "Y_att_poc = Y_att_raw[:N_TEST_TRACES_POC]\n",
    "\n",
    "# Global Min/Max calculation (should be based on the POC data now)\n",
    "GLOBAL_MIN = min(X_prof_poc.min(), X_att_poc.min())\n",
    "GLOBAL_MAX = max(X_prof_poc.max(), X_att_poc.max())\n",
    "\n",
    "# 1.5 Binary Label Simplification\n",
    "Y_prof_bin = to_binary_hw_detection(Y_prof_poc, TARGET_HW)\n",
    "Y_att_bin = to_binary_hw_detection(Y_att_poc, TARGET_HW)\n",
    "\n",
    "# 1.7 & 1.8 Windowing and Normalization\n",
    "U_train, Y_train = window_and_normalize(X_prof_poc, Y_prof_bin, WINDOW_SIZE, STRIDE, GLOBAL_MIN, GLOBAL_MAX)\n",
    "U_test, Y_test = window_and_normalize(X_att_poc, Y_att_bin, WINDOW_SIZE, STRIDE, GLOBAL_MIN, GLOBAL_MAX)\n",
    "\n",
    "# ... (rest of the save/print block remains the same)\n",
    "print(f\"NEW U_train shape (approx 697k steps): {U_train.shape}\") # Verify the size is now small\n",
    "\n",
    "print(\"\\n--- Final Data Structure ---\")\n",
    "print(f\"Training Input U_train shape: {U_train.shape}\")\n",
    "print(f\"Test Input U_test shape: {U_test.shape}\")\n",
    "\n",
    "# Save the prepared data for use in the next scripts\n",
    "np.save('U_train.npy', U_train)\n",
    "np.save('Y_train.npy', Y_train)\n",
    "np.save('U_test.npy', U_test)\n",
    "np.save('Y_test.npy', Y_test)\n",
    "print(\"Data saved to .npy files for Stage 2 & 3.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02b5f1ed-8825-47bf-a3e9-c79caad2bd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ASCAD:\n",
      "Train: (1000, 700) Test: (1000, 700)\n",
      "HW=4 positives (train): 239\n",
      "HW=4 positives (test) : 260\n",
      "✅ Correct trace-level dataset saved.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "# =========================================================\n",
    "# CONFIG\n",
    "# =========================================================\n",
    "FILE_PATH = r\"F:\\QRC-SCA-Project\\ASCAD_data\\ASCAD_data\\ASCAD_databases\\ASCAD.h5\"\n",
    "TARGET_HW = 4\n",
    "N_TRAIN = 1000\n",
    "N_TEST  = 1000\n",
    "\n",
    "# =========================================================\n",
    "# LOAD ASCAD\n",
    "# =========================================================\n",
    "with h5py.File(FILE_PATH, 'r') as f:\n",
    "    X_prof = np.array(f['Profiling_traces/traces'][:N_TRAIN])\n",
    "    Y_prof = np.array(f['Profiling_traces/labels'][:N_TRAIN])\n",
    "    X_att  = np.array(f['Attack_traces/traces'][:N_TEST])\n",
    "    Y_att  = np.array(f['Attack_traces/labels'][:N_TEST])\n",
    "\n",
    "print(\"Loaded ASCAD:\")\n",
    "print(\"Train:\", X_prof.shape, \"Test:\", X_att.shape)\n",
    "\n",
    "# =========================================================\n",
    "# TRACE-LEVEL BINARY HW LABELS (CORRECT)\n",
    "# =========================================================\n",
    "HW = np.array([bin(i).count(\"1\") for i in range(256)])\n",
    "\n",
    "Y_prof_hw = HW[Y_prof]\n",
    "Y_att_hw  = HW[Y_att]\n",
    "\n",
    "Y_prof_bin = (Y_prof_hw == TARGET_HW).astype(int)\n",
    "Y_att_bin  = (Y_att_hw == TARGET_HW).astype(int)\n",
    "\n",
    "print(f\"HW={TARGET_HW} positives (train):\", Y_prof_bin.sum())\n",
    "print(f\"HW={TARGET_HW} positives (test) :\", Y_att_bin.sum())\n",
    "\n",
    "# =========================================================\n",
    "# NORMALIZATION (TRACE-LEVEL)\n",
    "# =========================================================\n",
    "global_min = min(X_prof.min(), X_att.min())\n",
    "global_max = max(X_prof.max(), X_att.max())\n",
    "\n",
    "X_prof = (X_prof - global_min) / (global_max - global_min)\n",
    "X_att  = (X_att  - global_min) / (global_max - global_min)\n",
    "\n",
    "# =========================================================\n",
    "# SAVE\n",
    "# =========================================================\n",
    "np.save(\"U_train.npy\", X_prof.astype(np.float32))\n",
    "np.save(\"Y_train.npy\", Y_prof_bin.astype(np.int32))\n",
    "np.save(\"U_test.npy\",  X_att.astype(np.float32))\n",
    "np.save(\"Y_test.npy\",  Y_att_bin.astype(np.int32))\n",
    "\n",
    "print(\"✅ Correct trace-level dataset saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02c3f658-ab80-46a0-9829-23d8a16c9dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ASCAD...\n",
      "HW=4 positives (train): 239\n",
      "HW=4 positives (test) : 260\n",
      "Selected 25 POIs\n",
      "CPC feature dimension: 300\n",
      "Running ESN...\n",
      "\n",
      "--- FINAL CORRECT CPC + ESN RESULTS ---\n",
      "Optimal threshold : 0.23\n",
      "Accuracy          : 0.2810\n",
      "F1-Score          : 0.4140\n",
      "--------------------------------------\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 27 713]\n",
      " [  6 254]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# =====================================================\n",
    "# CONFIG\n",
    "# =====================================================\n",
    "ASCAD_PATH = r\"F:\\QRC-SCA-Project\\ASCAD_data\\ASCAD_data\\ASCAD_databases\\ASCAD.h5\"\n",
    "\n",
    "N_TRAIN = 1000\n",
    "N_TEST  = 1000\n",
    "TARGET_HW = 4\n",
    "\n",
    "N_POIS = 25\n",
    "N_x = 500\n",
    "\n",
    "SPECTRAL_RADIUS = 0.9\n",
    "INPUT_SCALING = 0.5\n",
    "SPARSITY = 0.9\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# =====================================================\n",
    "# LOAD DATA\n",
    "# =====================================================\n",
    "def load_ascad(path):\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        Xp = np.array(f[\"Profiling_traces/traces\"][:N_TRAIN])\n",
    "        Yp = np.array(f[\"Profiling_traces/labels\"][:N_TRAIN])\n",
    "        Xa = np.array(f[\"Attack_traces/traces\"][:N_TEST])\n",
    "        Ya = np.array(f[\"Attack_traces/labels\"][:N_TEST])\n",
    "    return Xp, Yp, Xa, Ya\n",
    "\n",
    "# =====================================================\n",
    "# LABEL PROCESSING\n",
    "# =====================================================\n",
    "HW = np.array([bin(i).count(\"1\") for i in range(256)])\n",
    "\n",
    "def to_binary_hw(y, target):\n",
    "    return (HW[y] == target).astype(int)\n",
    "\n",
    "# =====================================================\n",
    "# POI SELECTION\n",
    "# =====================================================\n",
    "def select_pois(X, k):\n",
    "    return np.argsort(np.var(X, axis=0))[-k:]\n",
    "\n",
    "# =====================================================\n",
    "# TRUE 2ND-ORDER CPC\n",
    "# =====================================================\n",
    "def cpc_features(X, pois):\n",
    "    Xp = X[:, pois]\n",
    "    Xc = Xp - Xp.mean(axis=0)\n",
    "\n",
    "    feats = []\n",
    "    for i in range(len(pois)):\n",
    "        for j in range(i + 1, len(pois)):\n",
    "            feats.append(Xc[:, i] * Xc[:, j])\n",
    "\n",
    "    return np.stack(feats, axis=1)\n",
    "\n",
    "# =====================================================\n",
    "# ESN\n",
    "# =====================================================\n",
    "def init_esn(n_in, n_res):\n",
    "    Win = np.random.uniform(-INPUT_SCALING, INPUT_SCALING, (n_res, n_in))\n",
    "    W = np.random.uniform(-1, 1, (n_res, n_res))\n",
    "\n",
    "    mask = np.random.rand(n_res, n_res) < SPARSITY\n",
    "    W *= mask\n",
    "\n",
    "    eigs = np.linalg.eigvals(W)\n",
    "    W *= SPECTRAL_RADIUS / np.max(np.abs(eigs))\n",
    "\n",
    "    return Win, W\n",
    "\n",
    "def esn_transform(X, Win, W):\n",
    "    R = np.zeros((X.shape[0], W.shape[0]))\n",
    "    for i in range(X.shape[0]):\n",
    "        x = np.zeros(W.shape[0])\n",
    "        for t in range(X.shape[1]):\n",
    "            u = np.array([X[i, t]])\n",
    "            x = np.tanh(W @ x + Win @ u)\n",
    "        R[i] = x\n",
    "    return R\n",
    "\n",
    "# =====================================================\n",
    "# MAIN\n",
    "# =====================================================\n",
    "print(\"Loading ASCAD...\")\n",
    "Xp, Yp, Xa, Ya = load_ascad(ASCAD_PATH)\n",
    "\n",
    "Yp_bin = to_binary_hw(Yp, TARGET_HW)\n",
    "Ya_bin = to_binary_hw(Ya, TARGET_HW)\n",
    "\n",
    "print(f\"HW={TARGET_HW} positives (train): {Yp_bin.sum()}\")\n",
    "print(f\"HW={TARGET_HW} positives (test) : {Ya_bin.sum()}\")\n",
    "\n",
    "# Normalize traces\n",
    "scaler = StandardScaler()\n",
    "Xp = scaler.fit_transform(Xp)\n",
    "Xa = scaler.transform(Xa)\n",
    "\n",
    "# POIs\n",
    "pois = select_pois(Xp, N_POIS)\n",
    "print(f\"Selected {len(pois)} POIs\")\n",
    "\n",
    "# CPC\n",
    "Xtr = cpc_features(Xp, pois)\n",
    "Xte = cpc_features(Xa, pois)\n",
    "print(f\"CPC feature dimension: {Xtr.shape[1]}\")\n",
    "\n",
    "# ESN\n",
    "Win, W = init_esn(1, N_x)\n",
    "print(\"Running ESN...\")\n",
    "\n",
    "Rtr = esn_transform(Xtr, Win, W)\n",
    "Rte = esn_transform(Xte, Win, W)\n",
    "\n",
    "# =====================================================\n",
    "# CLASSIFIER (IMBALANCE-AWARE)\n",
    "# =====================================================\n",
    "clf = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    class_weight=\"balanced\",\n",
    "    solver=\"lbfgs\"\n",
    ")\n",
    "clf.fit(Rtr, Yp_bin)\n",
    "\n",
    "# =====================================================\n",
    "# THRESHOLD OPTIMIZATION (CRITICAL)\n",
    "# =====================================================\n",
    "probs = clf.predict_proba(Rte)[:, 1]\n",
    "\n",
    "best_f1 = 0\n",
    "best_t = 0.5\n",
    "\n",
    "for t in np.linspace(0.05, 0.95, 60):\n",
    "    preds = (probs > t).astype(int)\n",
    "    f1 = f1_score(Ya_bin, preds)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_t = t\n",
    "\n",
    "pred = (probs > best_t).astype(int)\n",
    "\n",
    "# =====================================================\n",
    "# RESULTS\n",
    "# =====================================================\n",
    "acc = accuracy_score(Ya_bin, pred)\n",
    "f1  = f1_score(Ya_bin, pred)\n",
    "\n",
    "print(\"\\n--- FINAL CORRECT CPC + ESN RESULTS ---\")\n",
    "print(f\"Optimal threshold : {best_t:.2f}\")\n",
    "print(f\"Accuracy          : {acc:.4f}\")\n",
    "print(f\"F1-Score          : {f1:.4f}\")\n",
    "print(\"--------------------------------------\")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(Ya_bin, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028b3384-b3f2-43bb-a2a3-9e697644bbae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
